python3 efficientnetclassifier.py 
Loading DataSet
2021-10-13 12:57:00.339910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 12:57:00.347284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 12:57:00.347775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 12:57:00.348797: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-10-13 12:57:00.349489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 12:57:00.349972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 12:57:00.350407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 12:57:00.803469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 12:57:00.803931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 12:57:00.804343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 12:57:00.804712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4643 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:09:00.0, compute capability: 6.1
 
 Loading EfficientNet-Lite0 

2021-10-13 12:57:05.854328: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
hub_keras_layer_v1v2 (HubKer (None, 1280)              3413024   
_________________________________________________________________
dropout (Dropout)            (None, 1280)              0         
_________________________________________________________________
dense (Dense)                (None, 5)                 6405      
=================================================================
Total params: 3,419,429
Trainable params: 6,405
Non-trainable params: 3,413,024
_________________________________________________________________
None
/home/nikhil/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  warnings.warn(
Epoch 1/50
2021-10-13 12:57:09.598667: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8204
2021-10-13 12:57:09.947282: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
103/103 [==============================] - 11s 72ms/step - loss: 0.8522 - accuracy: 0.7849 - val_loss: 0.6713 - val_accuracy: 0.8687
Epoch 2/50
103/103 [==============================] - 7s 67ms/step - loss: 0.6576 - accuracy: 0.8908 - val_loss: 0.6483 - val_accuracy: 0.8813
Epoch 3/50
103/103 [==============================] - 7s 68ms/step - loss: 0.6210 - accuracy: 0.9087 - val_loss: 0.6377 - val_accuracy: 0.8813
Epoch 4/50
103/103 [==============================] - 7s 71ms/step - loss: 0.6023 - accuracy: 0.9205 - val_loss: 0.6344 - val_accuracy: 0.8813
Epoch 5/50
103/103 [==============================] - 7s 70ms/step - loss: 0.5865 - accuracy: 0.9408 - val_loss: 0.6333 - val_accuracy: 0.9000
Epoch 6/50
103/103 [==============================] - 7s 69ms/step - loss: 0.5776 - accuracy: 0.9417 - val_loss: 0.6335 - val_accuracy: 0.8875
Epoch 7/50
103/103 [==============================] - 8s 74ms/step - loss: 0.5688 - accuracy: 0.9445 - val_loss: 0.6361 - val_accuracy: 0.8938
Epoch 8/50
103/103 [==============================] - 8s 74ms/step - loss: 0.5649 - accuracy: 0.9472 - val_loss: 0.6379 - val_accuracy: 0.8875
Epoch 9/50
103/103 [==============================] - 7s 72ms/step - loss: 0.5578 - accuracy: 0.9436 - val_loss: 0.6306 - val_accuracy: 0.8875
Epoch 10/50
103/103 [==============================] - 7s 71ms/step - loss: 0.5540 - accuracy: 0.9542 - val_loss: 0.6285 - val_accuracy: 0.8938
Epoch 11/50
103/103 [==============================] - 7s 70ms/step - loss: 0.5477 - accuracy: 0.9590 - val_loss: 0.6336 - val_accuracy: 0.8875
Epoch 12/50
103/103 [==============================] - 7s 72ms/step - loss: 0.5463 - accuracy: 0.9572 - val_loss: 0.6373 - val_accuracy: 0.8687
Epoch 13/50
103/103 [==============================] - 7s 72ms/step - loss: 0.5398 - accuracy: 0.9633 - val_loss: 0.6346 - val_accuracy: 0.8813
Epoch 14/50
103/103 [==============================] - 7s 71ms/step - loss: 0.5366 - accuracy: 0.9666 - val_loss: 0.6304 - val_accuracy: 0.8750
Epoch 15/50
103/103 [==============================] - 7s 72ms/step - loss: 0.5375 - accuracy: 0.9612 - val_loss: 0.6287 - val_accuracy: 0.8750
Epoch 16/50
103/103 [==============================] - 7s 72ms/step - loss: 0.5348 - accuracy: 0.9672 - val_loss: 0.6300 - val_accuracy: 0.8875
Epoch 17/50
103/103 [==============================] - 7s 72ms/step - loss: 0.5319 - accuracy: 0.9615 - val_loss: 0.6338 - val_accuracy: 0.8750
Epoch 18/50
103/103 [==============================] - 7s 72ms/step - loss: 0.5326 - accuracy: 0.9639 - val_loss: 0.6296 - val_accuracy: 0.8875
Epoch 19/50
103/103 [==============================] - 7s 68ms/step - loss: 0.5299 - accuracy: 0.9688 - val_loss: 0.6283 - val_accuracy: 0.8938
Epoch 20/50
103/103 [==============================] - 7s 69ms/step - loss: 0.5247 - accuracy: 0.9709 - val_loss: 0.6304 - val_accuracy: 0.8875
Epoch 21/50
103/103 [==============================] - 7s 68ms/step - loss: 0.5288 - accuracy: 0.9663 - val_loss: 0.6302 - val_accuracy: 0.8875
Epoch 22/50
103/103 [==============================] - 7s 68ms/step - loss: 0.5213 - accuracy: 0.9736 - val_loss: 0.6324 - val_accuracy: 0.8687
Epoch 23/50
103/103 [==============================] - 7s 71ms/step - loss: 0.5237 - accuracy: 0.9715 - val_loss: 0.6341 - val_accuracy: 0.8875
Epoch 24/50
103/103 [==============================] - 8s 74ms/step - loss: 0.5214 - accuracy: 0.9751 - val_loss: 0.6296 - val_accuracy: 0.8813
Epoch 25/50
103/103 [==============================] - 7s 73ms/step - loss: 0.5234 - accuracy: 0.9727 - val_loss: 0.6330 - val_accuracy: 0.8750
Epoch 26/50
103/103 [==============================] - 8s 73ms/step - loss: 0.5175 - accuracy: 0.9769 - val_loss: 0.6347 - val_accuracy: 0.8875
Epoch 27/50
103/103 [==============================] - 8s 74ms/step - loss: 0.5171 - accuracy: 0.9739 - val_loss: 0.6283 - val_accuracy: 0.8938
Epoch 28/50
103/103 [==============================] - 8s 75ms/step - loss: 0.5200 - accuracy: 0.9742 - val_loss: 0.6307 - val_accuracy: 0.8938
Epoch 29/50
103/103 [==============================] - 8s 74ms/step - loss: 0.5186 - accuracy: 0.9757 - val_loss: 0.6311 - val_accuracy: 0.9000
Epoch 30/50
103/103 [==============================] - 8s 73ms/step - loss: 0.5176 - accuracy: 0.9730 - val_loss: 0.6276 - val_accuracy: 0.8938
Epoch 31/50
103/103 [==============================] - 8s 75ms/step - loss: 0.5169 - accuracy: 0.9751 - val_loss: 0.6271 - val_accuracy: 0.8750
Epoch 32/50
103/103 [==============================] - 7s 73ms/step - loss: 0.5188 - accuracy: 0.9724 - val_loss: 0.6286 - val_accuracy: 0.8750
Epoch 33/50
103/103 [==============================] - 7s 72ms/step - loss: 0.5185 - accuracy: 0.9724 - val_loss: 0.6280 - val_accuracy: 0.8813
Epoch 34/50
103/103 [==============================] - 7s 72ms/step - loss: 0.5165 - accuracy: 0.9766 - val_loss: 0.6310 - val_accuracy: 0.8875
Epoch 35/50
103/103 [==============================] - 7s 73ms/step - loss: 0.5152 - accuracy: 0.9791 - val_loss: 0.6287 - val_accuracy: 0.8750
Epoch 36/50
103/103 [==============================] - 8s 75ms/step - loss: 0.5126 - accuracy: 0.9766 - val_loss: 0.6309 - val_accuracy: 0.8750
Epoch 37/50
103/103 [==============================] - 8s 76ms/step - loss: 0.5152 - accuracy: 0.9751 - val_loss: 0.6292 - val_accuracy: 0.8750
Epoch 38/50
103/103 [==============================] - 8s 73ms/step - loss: 0.5110 - accuracy: 0.9769 - val_loss: 0.6320 - val_accuracy: 0.8687
Epoch 39/50
103/103 [==============================] - 7s 72ms/step - loss: 0.5093 - accuracy: 0.9772 - val_loss: 0.6286 - val_accuracy: 0.8625
Epoch 40/50
103/103 [==============================] - 8s 73ms/step - loss: 0.5083 - accuracy: 0.9809 - val_loss: 0.6329 - val_accuracy: 0.8750
Epoch 41/50
103/103 [==============================] - 7s 72ms/step - loss: 0.5086 - accuracy: 0.9754 - val_loss: 0.6314 - val_accuracy: 0.8687
Epoch 42/50
103/103 [==============================] - 7s 73ms/step - loss: 0.5117 - accuracy: 0.9769 - val_loss: 0.6317 - val_accuracy: 0.8750
Epoch 43/50
103/103 [==============================] - 8s 73ms/step - loss: 0.5088 - accuracy: 0.9794 - val_loss: 0.6308 - val_accuracy: 0.8750
Epoch 44/50
103/103 [==============================] - 8s 74ms/step - loss: 0.5065 - accuracy: 0.9815 - val_loss: 0.6306 - val_accuracy: 0.8687
Epoch 45/50
103/103 [==============================] - 8s 74ms/step - loss: 0.5079 - accuracy: 0.9766 - val_loss: 0.6297 - val_accuracy: 0.8750
Epoch 46/50
103/103 [==============================] - 8s 76ms/step - loss: 0.5079 - accuracy: 0.9775 - val_loss: 0.6328 - val_accuracy: 0.8687
Epoch 47/50
103/103 [==============================] - 8s 73ms/step - loss: 0.5089 - accuracy: 0.9769 - val_loss: 0.6332 - val_accuracy: 0.8813
Epoch 48/50
103/103 [==============================] - 8s 74ms/step - loss: 0.5045 - accuracy: 0.9818 - val_loss: 0.6322 - val_accuracy: 0.8875
Epoch 49/50
103/103 [==============================] - 8s 75ms/step - loss: 0.5043 - accuracy: 0.9845 - val_loss: 0.6327 - val_accuracy: 0.8875
Epoch 50/50
103/103 [==============================] - 8s 75ms/step - loss: 0.5067 - accuracy: 0.9809 - val_loss: 0.6333 - val_accuracy: 0.8750
 
 
 SUMMARY:  
 

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
hub_keras_layer_v1v2 (HubKer (None, 1280)              3413024   
_________________________________________________________________
dropout (Dropout)            (None, 1280)              0         
_________________________________________________________________
dense (Dense)                (None, 5)                 6405      
=================================================================
Total params: 3,419,429
Trainable params: 6,405
Non-trainable params: 3,413,024
_________________________________________________________________
 
 
 Results:  
 

6/6 [==============================] - 1s 110ms/step - loss: 0.5601 - accuracy: 0.9348
  Loss: 
 
0.5601372718811035
 
  accuracy: 
 
0.9347826242446899
2021-10-13 13:03:25.306765: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
2021-10-13 13:03:28.287702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 13:03:28.287966: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2021-10-13 13:03:28.288085: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session
2021-10-13 13:03:28.288477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 13:03:28.288738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 13:03:28.288978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 13:03:28.289292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 13:03:28.289565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 13:03:28.289907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4643 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:09:00.0, compute capability: 6.1
2021-10-13 13:03:28.322147: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize
  function_optimizer: Graph size after: 913 nodes (656), 923 edges (664), time = 17.745ms.
  function_optimizer: function_optimizer did nothing. time = 0.312ms.

2021-10-13 13:03:29.086214: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.
2021-10-13 13:03:29.086257: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.
2021-10-13 13:03:29.122412: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 3
WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.
2021-10-13 13:04:19.399979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 13:04:19.400277: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2021-10-13 13:04:19.400372: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session
2021-10-13 13:04:19.400716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 13:04:19.400974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 13:04:19.401210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 13:04:19.401648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 13:04:19.402099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-10-13 13:04:19.402290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4643 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:09:00.0, compute capability: 6.1
2021-10-13 13:04:19.441550: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize
  function_optimizer: Graph size after: 913 nodes (656), 923 edges (664), time = 23.068ms.
  function_optimizer: function_optimizer did nothing. time = 0.517ms.

2021-10-13 13:04:20.206526: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.
2021-10-13 13:04:20.206581: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.
2021-10-13 13:04:20.384880: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor efficientnet-lite0/model/stem/Relu6;sequential/hub_keras_layer_v1v2/StatefulPartitionedCall/efficientnet-lite0/model/stem/Relu6;efficientnet-lite0/model/stem/tpu_batch_normalization/FusedBatchNormV3;sequential/hub_keras_layer_v1v2/StatefulPartitionedCall/efficientnet-lite0/model/stem/tpu_batch_normalization/FusedBatchNormV3;efficientnet-lite0/model/blocks_0/tpu_batch_normalization/FusedBatchNormV3;sequential/hub_keras_layer_v1v2/StatefulPartitionedCall/efficientnet-lite0/model/blocks_0/tpu_batch_normalization/FusedBatchNormV3;efficientnet-lite0/model/blocks_0/depthwise_conv2d/depthwise;sequential/hub_keras_layer_v1v2/StatefulPartitionedCall/efficientnet-lite0/model/blocks_0/depthwise_conv2d/depthwise;efficientnet-lite0/model/stem/conv2d/Conv2D;sequential/hub_keras_layer_v1v2/StatefulPartitionedCall/efficientnet-lite0/model/stem/conv2d/Conv2D because it has fewer than 1024 elements (864).
2021-10-13 13:04:20.384936: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor efficientnet-lite0/model/blocks_0/tpu_batch_normalization/FusedBatchNormV3;sequential/hub_keras_layer_v1v2/StatefulPartitionedCall/efficientnet-lite0/model/blocks_0/tpu_batch_normalization/FusedBatchNormV3;efficientnet-lite0/model/blocks_0/depthwise_conv2d/depthwise;sequential/hub_keras_layer_v1v2/StatefulPartitionedCall/efficientnet-lite0/model/blocks_0/depthwise_conv2d/depthwise because it has fewer than 1024 elements (288).
2021-10-13 13:04:20.384945: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor efficientnet-lite0/model/blocks_0/conv2d/Conv2D;sequential/hub_keras_layer_v1v2/StatefulPartitionedCall/efficientnet-lite0/model/blocks_0/conv2d/Conv2D because it has fewer than 1024 elements (512).
2021-10-13 13:04:20.384955: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor efficientnet-lite0/model/blocks_1/tpu_batch_normalization_1/FusedBatchNormV3;sequential/hub_keras_layer_v1v2/StatefulPartitionedCall/efficientnet-lite0/model/blocks_1/tpu_batch_normalization_1/FusedBatchNormV3;efficientnet-lite0/model/blocks_1/depthwise_conv2d/depthwise;sequential/hub_keras_layer_v1v2/StatefulPartitionedCall/efficientnet-lite0/model/blocks_1/depthwise_conv2d/depthwise because it has fewer than 1024 elements (864).
 
 
 TF-LITE Conversion accuracy:  
 

 
  accuracy: 
 
{'accuracy': 0.8852459016393442}
 
 
 TF-LITE quantization accuracy:  
 

 
  accuracy: 
 
{'accuracy': 0.8852459016393442}

